{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Hoiy/kaggle-home-credit-default-risk/blob/master/model_nn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Vfabwzu_xQQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e785c14-6eea-403d-875b-27775ccf06ce"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dotenv\n",
        "from scipy import sparse\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "dotenv.load_dotenv('.env')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_GngGBsNAAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9db62d08-08d9-4800-9d0f-70646471a714"
      },
      "cell_type": "code",
      "source": [
        "!mkdir prep\n",
        "!gsutil rsync gs://{os.environ['GCP_BUCKET']}/prep prep"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘prep’: File exists\n",
            "Building synchronization state...\n",
            "Starting synchronization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B394WW1eHJYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2159333f-c0f2-4573-a4e0-cfa02a28401b"
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet('./prep/application_train.snappy.parquet')\n",
        "train.shape\n",
        "\n",
        "test = pd.read_parquet('./prep/application_test.snappy.parquet')\n",
        "test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48744, 1561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "6aU1wYHZHPE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78588050-a726-4fea-8cf8-629cc26943f0"
      },
      "cell_type": "code",
      "source": [
        "y_train = train.TARGET\n",
        "X_train = train.drop(columns=['TARGET'])\n",
        "X_test = test\n",
        "\n",
        "del train\n",
        "del test\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# def get_category_cols(df):\n",
        "#   cols = []\n",
        "#   for idx, dtype in df.dtypes.iteritems():\n",
        "#     if dtype in ['object', 'int64'] and (len(df[idx].unique()) / len(df[idx].dropna()) <= 0.1):\n",
        "#       cols.append(idx)\n",
        "\n",
        "#   return cols\n",
        "\n",
        "# cat_cols = get_category_cols(X_train)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "cat_cols = []\n",
        "cont_cols = []\n",
        "for col, dtype in tqdm(X_train.dtypes.iteritems()):\n",
        "  if dtype == 'object':\n",
        "    temp = pd.concat([X_train[col], X_test[col]]).astype('category')\n",
        "    X_train[col] = X_train[col].astype(temp.dtypes)\n",
        "    X_test[col] = X_test[col].astype(temp.dtypes)\n",
        "    cat_cols.append(col)\n",
        "  else:\n",
        "    cont_cols.append(col)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1561it [01:39, 15.67it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "TDh09d7iLZVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01a548df-ae4e-4cce-f0c6-c6328a8b2bc3"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "-HidjsVhMHho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.to_feather('X_train.feather')\n",
        "y_train.to_frame().to_feather('y_train.feather')\n",
        "X_test.to_feather('X_test.feather')\n",
        "import pickle\n",
        "with open('cols_type.pkl', 'wb') as f:\n",
        "  pickle.dump([cat_cols, cont_cols], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEWqzqYpM-n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "feefc85e-473f-4241-81b1-018bca4344eb"
      },
      "cell_type": "code",
      "source": [
        "X_train = pd.read_feather('X_train.feather')\n",
        "y_train = pd.read_feather('y_train.feather')['TARGET']\n",
        "import pickle\n",
        "with open('cols_type.pkl', 'rb') as f:\n",
        "  cat_cols, cont_cols = pickle.load(f)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/io/feather_format.py:112: FutureWarning: `nthreads` argument is deprecated, pass `use_threads` instead\n",
            "  return feather.read_dataframe(path, nthreads=nthreads)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HGt6jROdledZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d4246f95-d01c-45e7-eb85-56ac7c2a9e89"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input, Flatten, Activation, Reshape, Add, Average\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU, Conv1D, Reshape, MaxPooling1D, Concatenate, Dot\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.constraints import non_neg, unit_norm\n",
        "import keras.backend as K\n",
        "from keras.metrics import mse\n",
        "import tensorflow as tf\n",
        "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
        "\n",
        "DROPOUT = 0.2\n",
        "# REGULARIZATION = 1e-5\n",
        "# EMB_SIZE = 1\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def roc_auc_score(y_true, y_pred):\n",
        "    \"\"\" ROC AUC Score.\n",
        "    Approximates the Area Under Curve score, using approximation based on\n",
        "    the Wilcoxon-Mann-Whitney U statistic.\n",
        "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
        "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
        "    Measures overall performance for a full range of threshold levels.\n",
        "    Arguments:\n",
        "        y_pred: `Tensor`. Predicted values.\n",
        "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(\"RocAucScore\"):\n",
        "\n",
        "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
        "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
        "\n",
        "        pos = tf.expand_dims(pos, 0)\n",
        "        neg = tf.expand_dims(neg, 1)\n",
        "\n",
        "        # original paper suggests performance is robust to exact parameter choice\n",
        "        gamma = 0.2\n",
        "        p     = 3\n",
        "\n",
        "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
        "\n",
        "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
        "\n",
        "        return tf.reduce_sum(tf.pow(-masked, p))\n",
        "      \n",
        "      \n",
        "def auc(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    K.get_session().run(tf.local_variables_initializer())\n",
        "    return auc\n",
        "  \n",
        "  \n",
        "\n",
        "def build_model():\n",
        "#     zeros = Input(shape=(1, ))\n",
        "#     ones = Input(shape=(1, ))\n",
        "#     cat_inputs = []\n",
        "#     cat_embs = []\n",
        "#     for cat, s in zip(cat_cols, emb_size):\n",
        "#       inp = Input(shape=(1,), name=cat)\n",
        "#       emb = Embedding(train[cat].max()+1, s, embeddings_regularizer=l2(REGULARIZATION))(inp)\n",
        "#       emb = Flatten()(emb)\n",
        "#       emb = Activation('tanh')(emb)\n",
        "      \n",
        "#       cat_inputs.append(inp)\n",
        "#       cat_embs.append(emb)\n",
        "    \n",
        "    cont_inp = Input(shape=(len(cont_cols),))      \n",
        "\n",
        "    emb = Dropout(DROPOUT)(cont_inp)\n",
        "    emb = Dense(256, activation='selu')(emb)\n",
        "    emb = Dropout(DROPOUT)(emb)\n",
        "    emb = Dense(256, activation='selu')(emb)\n",
        "    emb = Dropout(DROPOUT)(emb)\n",
        "    out = Dense(1, activation='sigmoid')(emb)\n",
        "    \n",
        "    model = Model(inputs=cont_inp, outputs=out)\n",
        "    model.compile(\n",
        "#         loss=roc_auc_score,\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['binary_crossentropy', auc])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1393)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1393)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               356864    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 422,913\n",
            "Trainable params: 422,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UbUoAlt2pI88",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# val_period = ((train['activation_date'] >= '2017-03-15') & (train['activation_date'] <= '2017-03-16')) |\\\n",
        "#   ((train['activation_date'] >= '2017-03-22') & (train['activation_date'] <= '2017-03-23'))\n",
        "# train_period = ~val_period\n",
        "\n",
        "# BATCH_SIZE = 4096 * 2\n",
        "EPOCHS = 20000\n",
        "FILE_PATH = 'nn_model.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(FILE_PATH, monitor='val_loss', save_best_only=True)\n",
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "\n",
        "callbacks_list = [checkpoint, early] #early"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9X18OYRFygj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "\n",
        "# k_fold = KFold(n_splits=5, shuffle=True)\n",
        "# model = KerasRegressor(build_model, batch_size=BATCH_SIZE)\n",
        "# metrics = cross_val_score(\n",
        "#     model, \n",
        "#     [train[col] for col in cat_cols] + [train['price_std']], \n",
        "#     train['deal_probability'], \n",
        "#     cv=k_fold,\n",
        "#     n_jobs=1,\n",
        "#     fit_params={\n",
        "#         'validation_split': 0.2,\n",
        "#         'shuffle': True,\n",
        "#         'batch_size': BATCH_SIZE,\n",
        "#         'epochs': EPOCHS,\n",
        "#         'callbacks': callbacks_list\n",
        "#     }\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "koCdCQSbN9ni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Full training\n",
        "# train_inp = [train[train_period][col] for col in cat_cols] + [train[train_period][col] for col in cont_cols]\n",
        "# val_inp = [train[val_period][col] for col in cat_cols] + [train[val_period][col] for col in cont_cols]\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# model = KerasRegressor(build_model, batch_size=BATCH_SIZE)\n",
        "# model.fit(train_inp, train[train_period]['deal_probability'], **{\n",
        "#         'validation_data': (val_inp, train[val_period]['deal_probability']),\n",
        "#         'shuffle': True,\n",
        "#         'batch_size': BATCH_SIZE,\n",
        "#         'epochs': EPOCHS,\n",
        "#         'callbacks': callbacks_list\n",
        "# })\n",
        "model = KerasClassifier(build_model, batch_size=BATCH_SIZE)\n",
        "model.fit(X_train[cont_cols], y_train, **{\n",
        "        'validation_split': 0.2,\n",
        "        'shuffle': True,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'epochs': EPOCHS,\n",
        "        'callbacks': callbacks_list\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Wyvt3p6O2g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a1fe0dd-cd89-4a46-b84a-5c191fab22f0"
      },
      "cell_type": "code",
      "source": [
        "# from keras.models import load_model\n",
        "# model = load_model(FILE_PATH, custom_objects={'rmse': rmse})\n",
        "\n",
        "metric = model.score([train[col] for col in cat_cols] + [train[col] for col in cont_cols], train['deal_probability'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1503424/1503424 [==============================] - 17s 11us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F8Vghc8bm0mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d366437-0b4d-41a6-9578-b794ac7ad294"
      },
      "cell_type": "code",
      "source": [
        "metric"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.21996117967432383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "ndG63HKNYtCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SUBMISSION_FILE='baseline.csv'\n",
        "SUBMISSION_MESSAGE='\"Baseline %f\"'%metric\n",
        "\n",
        "test['deal_probability'] = model.predict(\n",
        "    [test[col] for col in cat_cols] + [test[col] for col in cont_cols],\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "test[['item_id', 'deal_probability']].to_csv(SUBMISSION_FILE, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMgx2I7ntqhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf21ada9-1746-421e-8323-4a19d6a421a4"
      },
      "cell_type": "code",
      "source": [
        "len(test['item_id']) == len(submission['item_id'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "tCZluGeOZHVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3dede8c4-2a6e-497b-f3e3-2eb7683e4c7c"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -f '{SUBMISSION_FILE}' -m '{SUBMISSION_MESSAGE}'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using competition: avito-demand-prediction\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.3.9.1 / client 1.3.8)\n",
            "Successfully submitted to Avito Demand Prediction Challenge"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9sGBq1HbjWoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a9ee7f95-374a-489b-db89-8ff218bacad0"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: kaggle competitions submit [-h] [-c COMPETITION] -f FILE_NAME -m\r\n",
            "                                  MESSAGE [-q]\r\n",
            "kaggle competitions submit: error: the following arguments are required: -f/--file, -m/--message\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8oHjisMgA1JF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88dac5a7-9490-4215-c3af-9c8a19f81539"
      },
      "cell_type": "code",
      "source": [
        "!echo \"{SUBMISSION_FILE}\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ywYx11DGA8bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "622726dc-11ee-4373-cc92-828f3904d248"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -m 'Baseline -0.22988' -f baseline.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/local/bin/kaggle\", line 11, in <module>\r\n",
            "    sys.exit(main())\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/cli.py\", line 48, in main\r\n",
            "    out = args.func(**command_args)\r\n",
            "TypeError: competition_submit_cli() got an unexpected keyword argument 'file_name'\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dXeNdA-zBReI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f581197d-6336-4e9d-ddac-6d219c839762"
      },
      "cell_type": "code",
      "source": [
        "!pip freeze | grep kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle==1.3.9\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Di8gYaemCpmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f6e31cd-3699-4175-b22d-9a0d1b44954a"
      },
      "cell_type": "code",
      "source": [
        "!kaggle --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kaggle API 1.3.8\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VFuL24UJFROd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}